{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNszB9rllBaF",
        "outputId": "57e1e642-3949-4d9a-d3e7-93f4e1d797d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=8a21f173e296320001be3cd2b27c8273d5e3871652be11c30ea86b848335218c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLj046aFc9UY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm import tqdm\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9AQ5GtEaaz5",
        "outputId": "697477b8-ab2f-4956-8073-cfccb3235aa8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQQZ5LayciIb"
      },
      "source": [
        "train_df=pd.read_csv(\"/content/drive/MyDrive/Amex_data/Training Data_2021.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Amex_data/Test Data_2021.csv\")\n",
        "train_df = train_df.replace([\"missing\",'na'],np.nan)\n",
        "test_df = test_df.replace([\"missing\",'na'],np.nan)\n",
        "\n",
        "train_df['mvar47'] = train_df['mvar47'].replace('C',0).replace('L',1)\n",
        "test_df['mvar47'] = test_df['mvar47'].replace('C',0).replace('L',1)\n",
        "\n",
        "train_df=train_df.astype('float')\n",
        "test_df=test_df.astype('float')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "\n",
        "\n",
        "train_df = train_df.drop(['application_key'],axis=1)\n",
        "\n",
        "test_df_copy = test_df.drop(['application_key'],axis=1)\n",
        "\n",
        "\n",
        "\n",
        "def rows_with_nan(df,thershold):\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for s in df.index:\n",
        "\n",
        "        if df.loc[[s]].isna().sum().sum() >=thershold:\n",
        "\n",
        "            res.append(s)\n",
        "\n",
        "\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "train_nan_rows = rows_with_nan(train_df,40)\n",
        "\n",
        "#test_nan_rows = rows_with_nan(test_df_copy,40)\n",
        "\n",
        "train_df = train_df.drop(train_nan_rows,axis=0)\n",
        "\n",
        "\n",
        "\n",
        "X_train = train_df.iloc[:,train_df.columns!='default_ind']\n",
        "\n",
        "Y_train = train_df['default_ind']\n",
        "\n",
        "\n",
        "#cat doubt: mvar28\n",
        "\n",
        "#Cat_feat = ['mvar16','mvar17','mvar18','mvar19','mvar20','mvar28','mvar34','mvar35','mvar36','mvar37','mvar38','mvar39','mvar43','mvar45','mvar46','mvar47']\n",
        "\n",
        "cols = list(X_train.columns)\n",
        "\n",
        "cols.remove('mvar47')\n",
        "\n",
        "\n",
        "\n",
        "#filling missing values for 'mvar21','mvar22','mvar23','mvar24','mvar25','mvar26'\n",
        "\n",
        "#filling with mean/median\n",
        "\n",
        "#filling with knn\n",
        "\n",
        "#filling with mean\n",
        "\n",
        "for i in cols:\n",
        "\n",
        "    X_train[i] = X_train[i].fillna(value=X_train[i].mean())\n",
        "\n",
        "for i in cols:\n",
        "\n",
        "    test_df_copy[i] = test_df_copy[i].fillna(value=test_df_copy[i].mean())\n",
        "\n",
        "\n",
        "\n",
        "#replace outliners with upper and lower value\n",
        "\n",
        "for i in cols :\n",
        "\n",
        "    q1 = np.nanpercentile(X_train[i], 25)\n",
        "\n",
        "    q3 = np.nanpercentile(X_train[i], 75)\n",
        "\n",
        "    # print(q1, q3)\n",
        "\n",
        "    IQR = q3-q1\n",
        "\n",
        "    lwr_bound = q1-(1.5*IQR)\n",
        "\n",
        "    upr_bound = q3+(1.5*IQR)\n",
        "\n",
        "    tenth_per = np.nanpercentile(X_train[i], 10)\n",
        "\n",
        "    ninty_per = np.nanpercentile(X_train[i], 90)\n",
        "\n",
        "    X_train[i] = np.where(\n",
        "\n",
        "        X_train[i] > upr_bound,\n",
        "\n",
        "        ninty_per,\n",
        "\n",
        "        np.where(\n",
        "\n",
        "            X_train[i] < lwr_bound,\n",
        "\n",
        "            tenth_per,\n",
        "\n",
        "            X_train[i]\n",
        "\n",
        "        )\n",
        "\n",
        "    )\n",
        "\n",
        "for i in cols :\n",
        "\n",
        "    q1 = np.nanpercentile(test_df_copy[i], 25)\n",
        "\n",
        "    q3 = np.nanpercentile(test_df_copy[i], 75)\n",
        "\n",
        "    # print(q1, q3)\n",
        "\n",
        "    IQR = q3-q1\n",
        "\n",
        "    lwr_bound = q1-(1.5*IQR)\n",
        "\n",
        "    upr_bound = q3+(1.5*IQR)\n",
        "\n",
        "    tenth_per = np.nanpercentile(test_df_copy[i], 10)\n",
        "\n",
        "    ninty_per = np.nanpercentile(test_df_copy[i], 90)\n",
        "\n",
        "\n",
        "    test_df_copy[i] = np.where(\n",
        "\n",
        "        test_df_copy[i] > upr_bound,\n",
        "\n",
        "        ninty_per,\n",
        "\n",
        "        np.where(\n",
        "\n",
        "            test_df_copy[i] < lwr_bound,\n",
        "\n",
        "            tenth_per,\n",
        "\n",
        "            test_df_copy[i]\n",
        "\n",
        "        )\n",
        "\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop('mvar5',axis=1)\n",
        "test_df_copy = test_df_copy.drop('mvar5',axis=1)"
      ],
      "metadata": {
        "id": "WNS5U3mzQ-am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor_matrix_train=X_train.corr().abs()\n",
        "\n",
        "upper_tri_train = cor_matrix_train.where(np.triu(np.ones(cor_matrix_train.shape),k=1).astype(np.bool))\n",
        "\n",
        "cor_matrix_test=test_df_copy.corr().abs()\n",
        "\n",
        "upper_tri_test = cor_matrix_test.where(np.triu(np.ones(cor_matrix_test.shape),k=1).astype(np.bool))\n",
        "\n",
        "to_drop = [column for column in upper_tri_train.columns if any(upper_tri_train[column] > 0.7)]\n",
        "\n",
        "print(to_drop)\n",
        "\n",
        "to_drop = [column for column in upper_tri_test.columns if any(upper_tri_test[column] > 0.7)]\n",
        "\n",
        "print(to_drop)\n",
        "\n",
        "\n",
        "X_train = X_train.drop(to_drop,axis=1)\n",
        "\n",
        "test_df_copy=test_df_copy.drop(to_drop,axis=1)\n",
        "\n",
        "#normalizing the dataset\n",
        "\n",
        "for col in cols:\n",
        "\n",
        "    try:\n",
        "\n",
        "        X_train[col]=(X_train[col]-X_train[col].min())/(X_train[col].max()-X_train[col].min())\n",
        "\n",
        "    except KeyError:\n",
        "\n",
        "        pass\n",
        "\n",
        "#normalizing the dataset\n",
        "\n",
        "for col in cols:\n",
        "\n",
        "    try:\n",
        "\n",
        "        test_df_copy[col]=(test_df_copy[col]-test_df_copy[col].min())/(test_df_copy[col].max()-test_df_copy[col].min())\n",
        "\n",
        "    except KeyError:\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saCCJYFHP-FB",
        "outputId": "a9641f2d-8eb7-49a7-eacd-69dc56da5376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mvar10', 'mvar17', 'mvar18', 'mvar20', 'mvar23', 'mvar26', 'mvar27', 'mvar32', 'mvar37', 'mvar42']\n",
            "['mvar10', 'mvar17', 'mvar18', 'mvar20', 'mvar23', 'mvar26', 'mvar27', 'mvar32', 'mvar37', 'mvar42']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQPOQFv-dI1i"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0oH3t74Mag5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train.drop('application_key',axis=1)\n",
        "# test_df_copy = test_df.drop('application_key',axis=1)"
      ],
      "metadata": {
        "id": "uVjg1Bm8rHjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMziybsqdLbH"
      },
      "source": [
        "X_train = X_train.drop(['application_key','mvar11','mvar15','mvar22','mvar23','mvar30','mvar31','mvar40','mvar41'],axis=1)\n",
        "test_df_copy = test_df.drop(['application_key','mvar11','mvar15','mvar22','mvar23','mvar30','mvar31','mvar40','mvar41'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP2S6qJpdNjJ"
      },
      "source": [
        "Cat_feat = ['mvar16','mvar17','mvar18','mvar19','mvar20','mvar34','mvar35','mvar36','mvar37','mvar38','mvar39','mvar43','mvar45','mvar46','mvar47_C','mvar47_L']\n",
        "cols = list(X_train.columns)\n",
        "for i in Cat_feat:\n",
        "    cols.remove(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJimMA3vtczN"
      },
      "source": [
        "cols.remove('mvar4')\n",
        "cols.remove('mvar5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-G3a248dT2y"
      },
      "source": [
        "#replace outliners with upper and lower value\n",
        "for i in cols :\n",
        "    q1 = np.nanpercentile(X_train[i], 25)\n",
        "    q3 = np.nanpercentile(X_train[i], 75)\n",
        "    # print(q1, q3)\n",
        "    IQR = q3-q1\n",
        "    lwr_bound = q1-(1.5*IQR)\n",
        "    upr_bound = q3+(1.5*IQR)\n",
        "    tenth_per = np.nanpercentile(X_train[i], 10)\n",
        "    ninty_per = np.nanpercentile(X_train[i], 90)\n",
        "\n",
        "    X_train[i] = np.where(\n",
        "        X_train[i] > upr_bound,\n",
        "        ninty_per,\n",
        "        np.where(\n",
        "            X_train[i] < lwr_bound,\n",
        "            tenth_per,\n",
        "            X_train[i]\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyLAWF6DdW7G"
      },
      "source": [
        "for i in cols :\n",
        "    q1 = np.nanpercentile(test_df_copy[i], 25)\n",
        "    q3 = np.nanpercentile(test_df_copy[i], 75)\n",
        "    # print(q1, q3)\n",
        "    IQR = q3-q1\n",
        "    lwr_bound = q1-(1.5*IQR)\n",
        "    upr_bound = q3+(1.5*IQR)\n",
        "    tenth_per = np.nanpercentile(test_df_copy[i], 10)\n",
        "    ninty_per = np.nanpercentile(test_df_copy[i], 90)\n",
        "\n",
        "    test_df_copy[i] = np.where(\n",
        "        test_df_copy[i] > upr_bound,\n",
        "        ninty_per,\n",
        "        np.where(\n",
        "            test_df_copy[i] < lwr_bound,\n",
        "            tenth_per,\n",
        "            test_df_copy[i]\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4CMklUOvN0O"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfj_WhCvdYU5"
      },
      "source": [
        "#filling missing values for 'mvar21','mvar22','mvar23','mvar24','mvar25','mvar26'\n",
        "#filling with mean/median\n",
        "#filling with knn\n",
        "#filling with mean\n",
        "for i in cols+['mvar4','mvar5']:\n",
        "    X_train[i] = X_train[i].fillna(method='ffill')\n",
        "for i in cols+['mvar4','mvar5']:\n",
        "    test_df_copy[i] = test_df_copy[i].fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "CrOiOp8cdahe",
        "outputId": "3187f132-b850-44e6-8999-2f665802235c"
      },
      "source": [
        "X_train.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mvar1</th>\n",
              "      <th>mvar2</th>\n",
              "      <th>mvar3</th>\n",
              "      <th>mvar4</th>\n",
              "      <th>mvar5</th>\n",
              "      <th>mvar6</th>\n",
              "      <th>mvar7</th>\n",
              "      <th>mvar8</th>\n",
              "      <th>mvar9</th>\n",
              "      <th>mvar10</th>\n",
              "      <th>mvar12</th>\n",
              "      <th>mvar13</th>\n",
              "      <th>mvar14</th>\n",
              "      <th>mvar16</th>\n",
              "      <th>mvar17</th>\n",
              "      <th>mvar18</th>\n",
              "      <th>mvar19</th>\n",
              "      <th>mvar20</th>\n",
              "      <th>mvar21</th>\n",
              "      <th>mvar24</th>\n",
              "      <th>mvar25</th>\n",
              "      <th>mvar26</th>\n",
              "      <th>mvar27</th>\n",
              "      <th>mvar28</th>\n",
              "      <th>mvar29</th>\n",
              "      <th>mvar32</th>\n",
              "      <th>mvar33</th>\n",
              "      <th>mvar34</th>\n",
              "      <th>mvar35</th>\n",
              "      <th>mvar36</th>\n",
              "      <th>mvar37</th>\n",
              "      <th>mvar38</th>\n",
              "      <th>mvar39</th>\n",
              "      <th>mvar42</th>\n",
              "      <th>mvar43</th>\n",
              "      <th>mvar44</th>\n",
              "      <th>mvar45</th>\n",
              "      <th>mvar46</th>\n",
              "      <th>mvar47_C</th>\n",
              "      <th>mvar47_L</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82995</th>\n",
              "      <td>1748.0</td>\n",
              "      <td>0.3044</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20114.0</td>\n",
              "      <td>5574.0</td>\n",
              "      <td>77386.0</td>\n",
              "      <td>81647.0</td>\n",
              "      <td>18228.9</td>\n",
              "      <td>38049.0</td>\n",
              "      <td>148650.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>98.702</td>\n",
              "      <td>90.11</td>\n",
              "      <td>3219.0</td>\n",
              "      <td>8091.0</td>\n",
              "      <td>8091.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8091.0</td>\n",
              "      <td>635.0</td>\n",
              "      <td>16.0833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.04348</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.48002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82996</th>\n",
              "      <td>1846.0</td>\n",
              "      <td>0.3044</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>793.0</td>\n",
              "      <td>18608.0</td>\n",
              "      <td>18608.0</td>\n",
              "      <td>63820.0</td>\n",
              "      <td>29187.0</td>\n",
              "      <td>7863.0</td>\n",
              "      <td>38049.0</td>\n",
              "      <td>79280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.885</td>\n",
              "      <td>17.27</td>\n",
              "      <td>3207.0</td>\n",
              "      <td>2342.0</td>\n",
              "      <td>2342.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>7969.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>21.3333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.46925</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82997</th>\n",
              "      <td>1907.0</td>\n",
              "      <td>0.0381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2478.0</td>\n",
              "      <td>24775.0</td>\n",
              "      <td>19820.0</td>\n",
              "      <td>100294.0</td>\n",
              "      <td>79483.0</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>38049.0</td>\n",
              "      <td>99100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.967</td>\n",
              "      <td>3.54</td>\n",
              "      <td>2038.0</td>\n",
              "      <td>5049.0</td>\n",
              "      <td>5049.0</td>\n",
              "      <td>30386.0</td>\n",
              "      <td>5536.0</td>\n",
              "      <td>938.0</td>\n",
              "      <td>4.5833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.67960</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82998</th>\n",
              "      <td>1744.0</td>\n",
              "      <td>1.8301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>917.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>92071.2</td>\n",
              "      <td>2218.0</td>\n",
              "      <td>656.0</td>\n",
              "      <td>4108.0</td>\n",
              "      <td>9910.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.967</td>\n",
              "      <td>17.70</td>\n",
              "      <td>2488.0</td>\n",
              "      <td>5445.0</td>\n",
              "      <td>5445.0</td>\n",
              "      <td>760.0</td>\n",
              "      <td>6631.0</td>\n",
              "      <td>1139.0</td>\n",
              "      <td>1.5833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.09375</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.45317</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82999</th>\n",
              "      <td>1832.0</td>\n",
              "      <td>1.5561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>7928.0</td>\n",
              "      <td>7928.0</td>\n",
              "      <td>92071.2</td>\n",
              "      <td>58977.0</td>\n",
              "      <td>19548.0</td>\n",
              "      <td>38049.0</td>\n",
              "      <td>208110.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44.752</td>\n",
              "      <td>17.92</td>\n",
              "      <td>2390.0</td>\n",
              "      <td>7026.0</td>\n",
              "      <td>7026.0</td>\n",
              "      <td>30386.0</td>\n",
              "      <td>10098.0</td>\n",
              "      <td>1257.0</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.83278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        mvar1   mvar2  mvar3  mvar4  ...  mvar45  mvar46  mvar47_C  mvar47_L\n",
              "82995  1748.0  0.3044    0.0    0.0  ...     0.0     0.0       0.0       1.0\n",
              "82996  1846.0  0.3044    0.0    0.0  ...    -1.0     0.0       0.0       1.0\n",
              "82997  1907.0  0.0381    0.0    0.0  ...    -1.0     0.0       0.0       1.0\n",
              "82998  1744.0  1.8301    0.0    0.0  ...    -1.0     0.0       0.0       1.0\n",
              "82999  1832.0  1.5561    0.0    0.0  ...     0.0     0.0       0.0       1.0\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bIyidWcdftM"
      },
      "source": [
        "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# def calc_vif(X):\n",
        "\n",
        "#     # Calculating VIF\n",
        "#     vif = pd.DataFrame()\n",
        "#     vif[\"variables\"] = X.columns\n",
        "#     vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "#     return(vif)\n",
        "# vifs = calc_vif(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_vcP-05euL6"
      },
      "source": [
        "cor_matrix=X_train.corr().abs()\n",
        "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWC4oyIrfcEZ",
        "outputId": "a56f4d00-cfda-4aa6-fa90-11f436e4f798"
      },
      "source": [
        "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.7)]\n",
        "print(to_drop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mvar10', 'mvar17', 'mvar18', 'mvar20', 'mvar27', 'mvar32', 'mvar37', 'mvar42', 'mvar47_L']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYREVpUf2Ld"
      },
      "source": [
        "X_train = X_train.drop(to_drop,axis=1)\n",
        "test_df_copy=test_df_copy.drop(to_drop,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI5ehzeJf5M7",
        "outputId": "28415cb8-5f41-4b7d-b652-ac5da740cef5"
      },
      "source": [
        "X_train.shape, test_df_copy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((83000, 31), (47000, 31))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlSJWbtGmytn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPKCA0jyhW0y"
      },
      "source": [
        "#normalizing the dataset\n",
        "for col in cols+['mvar4','mvar5']:\n",
        "  try:\n",
        "    X_train[col]=(X_train[col]-X_train[col].min())/(X_train[col].max()-X_train[col].min())\n",
        "  except KeyError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhtu8AyRh0Ul"
      },
      "source": [
        "#normalizing the dataset\n",
        "for col in cols+['mvar4','mvar5']:\n",
        "  try:\n",
        "    test_df_copy[col]=(test_df_copy[col]-test_df_copy[col].min())/(test_df_copy[col].max()-test_df_copy[col].min())\n",
        "  except KeyError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WKw1wIBg2Vy"
      },
      "source": [
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,balanced_accuracy_score\n",
        "#mytrain = mytrain.drop(['mvar22','mvar23','mvar25'],axis=1)\n",
        "X = X_train\n",
        "Y = Y_train\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_n9lkTzjQW8",
        "outputId": "83794d2d-7bcf-47e7-e1f3-adfd4a406df2"
      },
      "source": [
        "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((57725, 36), (57725,), (24740, 36), (24740,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1lyi5SyjWe3",
        "outputId": "455b8777-7560-4bed-eee9-b03d6980a5b7"
      },
      "source": [
        "# lr = LogisticRegression()\n",
        "# lr.fit(x_train,y_train)\n",
        "# preds = lr.predict(x_test)\n",
        "# print(\"confusion matrix:\",confusion_matrix(y_test,preds))\n",
        "# print(\"accuracy_score:\",accuracy_score(y_test,preds))\n",
        "# print(\"recall_score:\",recall_score(y_test,preds))\n",
        "# print(\"f1_score:\",f1_score(y_test,preds))\n",
        "# print(\"precision_score:\",precision_score(y_test,preds))\n",
        "# print(\"balanced_accuracy_score:\",balanced_accuracy_score(y_test,preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: [[16229  1525]\n",
            " [ 4255  2891]]\n",
            "accuracy_score: 0.7678714859437751\n",
            "recall_score: 0.4045619927232018\n",
            "f1_score: 0.5000864902266045\n",
            "precision_score: 0.6546648550724637\n",
            "balanced_accuracy_score: 0.6593329283205961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0bIvFPdpwtS",
        "outputId": "b6fef41e-349f-4356-e38c-a5db33d48365"
      },
      "source": [
        "# preds1 = lr.predict(x_train)\n",
        "# print(\"confusion matrix:\",confusion_matrix(y_train,preds1))\n",
        "# print(\"accuracy_score:\",accuracy_score(y_train,preds1))\n",
        "# print(\"recall_score:\",recall_score(y_train,preds1))\n",
        "# print(\"f1_score:\",f1_score(y_train,preds1))\n",
        "# print(\"precision_score:\",precision_score(y_train,preds1))\n",
        "# print(\"balanced_accuracy_score:\",balanced_accuracy_score(y_train,preds1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: [[37872  3519]\n",
            " [10133  6576]]\n",
            "accuracy_score: 0.765025817555938\n",
            "recall_score: 0.39356035669399725\n",
            "f1_score: 0.49067303387554095\n",
            "precision_score: 0.6514115898959881\n",
            "balanced_accuracy_score: 0.6542709372076205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lli6_Rgjxi8r"
      },
      "source": [
        "## Using Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,balanced_accuracy_score\n",
        "#mytrain = mytrain.drop(['mvar22','mvar23','mvar25'],axis=1)\n",
        "X = X_train\n",
        "Y = Y_train\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)"
      ],
      "metadata": {
        "id": "6pifnNwqQnE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "HkkMGxB1QzQc",
        "outputId": "419ad33e-b861-4e70-9477-6616b3c7faf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mvar1</th>\n",
              "      <th>mvar2</th>\n",
              "      <th>mvar3</th>\n",
              "      <th>mvar4</th>\n",
              "      <th>mvar6</th>\n",
              "      <th>mvar7</th>\n",
              "      <th>mvar8</th>\n",
              "      <th>mvar9</th>\n",
              "      <th>mvar11</th>\n",
              "      <th>mvar12</th>\n",
              "      <th>mvar13</th>\n",
              "      <th>mvar14</th>\n",
              "      <th>mvar15</th>\n",
              "      <th>mvar16</th>\n",
              "      <th>mvar19</th>\n",
              "      <th>mvar21</th>\n",
              "      <th>mvar22</th>\n",
              "      <th>mvar24</th>\n",
              "      <th>mvar25</th>\n",
              "      <th>mvar28</th>\n",
              "      <th>mvar29</th>\n",
              "      <th>mvar30</th>\n",
              "      <th>mvar31</th>\n",
              "      <th>mvar33</th>\n",
              "      <th>mvar34</th>\n",
              "      <th>mvar35</th>\n",
              "      <th>mvar36</th>\n",
              "      <th>mvar38</th>\n",
              "      <th>mvar39</th>\n",
              "      <th>mvar40</th>\n",
              "      <th>mvar41</th>\n",
              "      <th>mvar43</th>\n",
              "      <th>mvar44</th>\n",
              "      <th>mvar45</th>\n",
              "      <th>mvar46</th>\n",
              "      <th>mvar47</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.441758</td>\n",
              "      <td>0.543290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.147850</td>\n",
              "      <td>0.018620</td>\n",
              "      <td>0.470326</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.402656</td>\n",
              "      <td>0.081948</td>\n",
              "      <td>0.531392</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.717720</td>\n",
              "      <td>0.916641</td>\n",
              "      <td>0.477150</td>\n",
              "      <td>0.340554</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.340957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044985</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.615677</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.265881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025895</td>\n",
              "      <td>0.185139</td>\n",
              "      <td>0.183371</td>\n",
              "      <td>0.212438</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.047958</td>\n",
              "      <td>0.051595</td>\n",
              "      <td>0.182799</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562065</td>\n",
              "      <td>0.097207</td>\n",
              "      <td>0.031700</td>\n",
              "      <td>0.239460</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171607</td>\n",
              "      <td>0.549339</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.289101</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.615006</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.549451</td>\n",
              "      <td>0.131413</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414681</td>\n",
              "      <td>0.062336</td>\n",
              "      <td>0.394519</td>\n",
              "      <td>0.396479</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.437280</td>\n",
              "      <td>0.414025</td>\n",
              "      <td>0.326488</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.217686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.433571</td>\n",
              "      <td>0.443419</td>\n",
              "      <td>0.466520</td>\n",
              "      <td>0.412352</td>\n",
              "      <td>0.022017</td>\n",
              "      <td>0.347803</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.629477</td>\n",
              "      <td>0.733563</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.536264</td>\n",
              "      <td>0.072029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.503173</td>\n",
              "      <td>0.649903</td>\n",
              "      <td>0.286535</td>\n",
              "      <td>0.236695</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.361347</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.433571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304682</td>\n",
              "      <td>0.002995</td>\n",
              "      <td>0.450797</td>\n",
              "      <td>0.549339</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.425604</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.289101</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.502214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.641758</td>\n",
              "      <td>0.003876</td>\n",
              "      <td>0.013201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.930693</td>\n",
              "      <td>0.135044</td>\n",
              "      <td>0.317704</td>\n",
              "      <td>0.093054</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.141491</td>\n",
              "      <td>0.743200</td>\n",
              "      <td>0.531392</td>\n",
              "      <td>0.980528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.154617</td>\n",
              "      <td>0.081256</td>\n",
              "      <td>0.189671</td>\n",
              "      <td>0.186583</td>\n",
              "      <td>0.016027</td>\n",
              "      <td>0.203656</td>\n",
              "      <td>0.549339</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034605</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.289101</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.921913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82995</th>\n",
              "      <td>0.556044</td>\n",
              "      <td>0.099980</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.494408</td>\n",
              "      <td>0.322331</td>\n",
              "      <td>0.901598</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918335</td>\n",
              "      <td>0.637671</td>\n",
              "      <td>0.569843</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.747456</td>\n",
              "      <td>0.974902</td>\n",
              "      <td>0.595100</td>\n",
              "      <td>0.749825</td>\n",
              "      <td>0.000987</td>\n",
              "      <td>0.608712</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.629477</td>\n",
              "      <td>0.664358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.446441</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82996</th>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.346822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.201320</td>\n",
              "      <td>0.457390</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.743546</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.492929</td>\n",
              "      <td>0.918335</td>\n",
              "      <td>0.340091</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114054</td>\n",
              "      <td>0.747030</td>\n",
              "      <td>0.033042</td>\n",
              "      <td>0.599534</td>\n",
              "      <td>0.549339</td>\n",
              "      <td>0.629477</td>\n",
              "      <td>0.882350</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.289101</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.434976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82997</th>\n",
              "      <td>0.905495</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.629094</td>\n",
              "      <td>0.608977</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.983701</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.186063</td>\n",
              "      <td>0.918335</td>\n",
              "      <td>0.425114</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074681</td>\n",
              "      <td>0.443419</td>\n",
              "      <td>0.023379</td>\n",
              "      <td>0.474726</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416491</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.186851</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.658909</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82998</th>\n",
              "      <td>0.547253</td>\n",
              "      <td>0.601097</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125920</td>\n",
              "      <td>0.022540</td>\n",
              "      <td>0.028682</td>\n",
              "      <td>0.983701</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>0.041124</td>\n",
              "      <td>0.109763</td>\n",
              "      <td>0.042511</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.433571</td>\n",
              "      <td>0.260354</td>\n",
              "      <td>0.116893</td>\n",
              "      <td>0.579548</td>\n",
              "      <td>0.025012</td>\n",
              "      <td>0.498872</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.629477</td>\n",
              "      <td>0.062284</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.289101</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.417857</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82999</th>\n",
              "      <td>0.740659</td>\n",
              "      <td>0.511102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257933</td>\n",
              "      <td>0.194873</td>\n",
              "      <td>0.458457</td>\n",
              "      <td>0.983701</td>\n",
              "      <td>0.538781</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918335</td>\n",
              "      <td>0.892739</td>\n",
              "      <td>0.625034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.338416</td>\n",
              "      <td>0.616413</td>\n",
              "      <td>0.118346</td>\n",
              "      <td>0.556720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.759705</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.629477</td>\n",
              "      <td>0.003463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.821981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>82465 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          mvar1     mvar2     mvar3  mvar4  ...    mvar44  mvar45  mvar46  mvar47\n",
              "0      0.441758  0.543290  0.000000    0.0  ...  0.615677     1.0     0.0     0.0\n",
              "1      0.771429  0.265881  0.000000    0.0  ...  0.615006     1.0     1.0     1.0\n",
              "2      0.549451  0.131413  0.000000    0.0  ...  1.000000     1.0     0.0     0.0\n",
              "3      0.536264  0.072029  0.000000    0.0  ...  0.502214     0.0     0.0     1.0\n",
              "4      0.641758  0.003876  0.013201    0.0  ...  0.921913     1.0     1.0     1.0\n",
              "...         ...       ...       ...    ...  ...       ...     ...     ...     ...\n",
              "82995  0.556044  0.099980  0.000000    0.0  ...  0.446441     0.0     0.0     1.0\n",
              "82996  0.771429  0.346822  0.000000    0.0  ...  0.434976     1.0     0.0     1.0\n",
              "82997  0.905495  0.012514  0.000000    0.0  ...  0.658909     1.0     0.0     1.0\n",
              "82998  0.547253  0.601097  0.000000    0.0  ...  0.417857     1.0     0.0     1.0\n",
              "82999  0.740659  0.511102  0.000000    0.0  ...  0.821981     0.0     0.0     1.0\n",
              "\n",
              "[82465 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0pHlf-xr5N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "4d738fe9-de3c-4232-88df-f9db2d7cf400"
      },
      "source": [
        "import optuna \n",
        "import joblib\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "def objective(trial: Trial,X,y) -> float:\n",
        "\n",
        "    param = {\n",
        "                \"n_estimators\" : trial.suggest_int('n_estimators', 500, 2000),\n",
        "                \"num_leaves\": trial.suggest_int('num_leaves',0,50),\n",
        "                'max_depth':trial.suggest_int('max_depth', 2, 10),\n",
        "                'reg_alpha':trial.suggest_loguniform('reg_alpha', 0.01, 5),\n",
        "                'reg_lambda':trial.suggest_loguniform('reg_lambda', 0.1, 5),\n",
        "                'min_split_gain ':trial.suggest_loguniform('min_split_gain ',0.1,5),\n",
        "                'min_child_samples':trial.suggest_int('min_child_samples',0,50),\n",
        "                'min_child_weight':trial.suggest_loguniform('min_child_weight', 0.01, 5),\n",
        "                'learning_rate':trial.suggest_loguniform('learning_rate',0.05,0.5),\n",
        "                'nthread' : -1,\n",
        "                'scale_pos_weight':2.6\n",
        "            }\n",
        "    \n",
        "    model = LGBMClassifier(device=\"gpu\",**param)\n",
        "    \n",
        "    return cross_val_score(model, X, y, cv=3,scoring='roc_auc').mean()\n",
        "  \n",
        "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
        "study.optimize(lambda trial : objective(trial,X,Y),n_trials= 10)\n",
        "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-15 13:33:42,194]\u001b[0m A new study created in memory with name: no-name-e5ad2264-e0f3-450c-a50d-282453a6015d\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:42,945]\u001b[0m Trial 0 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:43,701]\u001b[0m Trial 1 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:44,452]\u001b[0m Trial 2 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:45,195]\u001b[0m Trial 3 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:45,935]\u001b[0m Trial 4 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:46,681]\u001b[0m Trial 5 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:47,425]\u001b[0m Trial 6 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:48,169]\u001b[0m Trial 7 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:48,948]\u001b[0m Trial 8 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2021-12-15 13:33:49,700]\u001b[0m Trial 9 failed, because the objective function returned nan.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ce2114204292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial: score {},\\nparams {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mbest_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2usuI-ATQHgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3leoLjv-yqqA",
        "outputId": "cd102809-08f8-4330-f53e-0075bbd7253f"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "param = {'n_estimators': 526, 'max_depth': 5, 'reg_alpha': 0, 'reg_lambda': 4, 'min_child_weight': 0, 'gamma': 4, 'learning_rate': 0.05426408985502295, 'colsample_bytree': 0.38,'scale_pos_weight':2.5}\n",
        "model = XGBClassifier(**param)\n",
        "#lr = LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "preds = model.predict(x_test)\n",
        "print(\"confusion matrix:\",confusion_matrix(y_test,preds))\n",
        "print(\"accuracy_score:\",accuracy_score(y_test,preds))\n",
        "print(\"recall_score:\",recall_score(y_test,preds))\n",
        "print(\"f1_score:\",f1_score(y_test,preds))\n",
        "print(\"precision_score:\",precision_score(y_test,preds))\n",
        "print(\"balanced_accuracy_score:\",balanced_accuracy_score(y_test,preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: [[13096  4658]\n",
            " [ 2203  4943]]\n",
            "accuracy_score: 0.7244578313253012\n",
            "recall_score: 0.6917156451161489\n",
            "f1_score: 0.5903146832268465\n",
            "precision_score: 0.5148422039370899\n",
            "balanced_accuracy_score: 0.7146761170269266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'n_estimators': 526, 'max_depth': 5, 'reg_alpha': 0, 'reg_lambda': 4, 'min_child_weight': 0, 'gamma': 4, 'learning_rate': 0.05426408985502295, 'colsample_bytree': 0.38,'scale_pos_weight':2.5}\n",
        "model = XGBClassifier(**param)\n",
        "#lr = LogisticRegression()\n",
        "model.fit(X,Y)\n",
        "preds = model.predict(test_df_copy)"
      ],
      "metadata": {
        "id": "fp1TQEFBy_kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCtNW0m8z7Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['default_ind'] = preds\n",
        "test_df[['application_key','default_ind']].astype(int).to_csv(\"submission4.csv\",index=False,header=False)"
      ],
      "metadata": {
        "id": "tGVm2OpXz5zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Random Forest"
      ],
      "metadata": {
        "id": "bKZMHuM-ka-y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5xdMFFDMj-9"
      },
      "source": [
        "#n_estimators = 50, max_depth=15\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import validation_curve\n",
        "train_scoreNum, test_scoreNum = validation_curve(\n",
        "                                RandomForestClassifier(n_estimators=50,max_depth=15,min_samples_split=2,min_samples_leaf=1),\n",
        "                                X = x_train, y = y_train, \n",
        "                                param_name = 'min_samples_leaf', \n",
        "                                param_range = [1,2,3,4,5], cv = 3,scoring = \"roc_auc\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train_score = np.mean(train_scoreNum, axis = 1)\n",
        "std_train_score = np.std(train_scoreNum, axis = 1)\n",
        " \n",
        "# Calculating mean and standard deviation of testing score\n",
        "mean_test_score = np.mean(test_scoreNum, axis = 1)\n",
        "std_test_score = np.std(test_scoreNum, axis = 1)\n",
        " \n",
        "# Plot mean accuracy scores for training and testing scores\n",
        "plt.plot([1,2,3,4,5], mean_train_score,\n",
        "     label = \"Training Score\", color = 'b')\n",
        "plt.plot([1,2,3,4,5], mean_test_score,\n",
        "   label = \"Cross Validation Score\", color = 'g')\n",
        " \n",
        "# Creating the plot\n",
        "plt.title(\"Validation Curve with rfClassifier\")\n",
        "plt.xlabel(\"Number of max_depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "bxdVlqb2Iuhy",
        "outputId": "0e5ed1f9-a844-4f0b-dec6-8471d3844eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forestVC = RandomForestClassifier(n_estimators=50,max_depth=15,min_samples_split=2,min_samples_leaf=1) \n",
        "modelVC = forestVC.fit(x_train, y_train) "
      ],
      "metadata": {
        "id": "I86ZgLjLhB1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaNwahhZhPRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f029cb33-3140-42f3-87ec-26cb13978285"
      },
      "source": [
        "preds = modelVC.predict(x_test)\n",
        "print(\"confusion matrix:\",confusion_matrix(y_test,preds))\n",
        "print(\"accuracy_score:\",accuracy_score(y_test,preds))\n",
        "print(\"recall_score:\",recall_score(y_test,preds))\n",
        "print(\"f1_score:\",f1_score(y_test,preds))\n",
        "print(\"precision_score:\",precision_score(y_test,preds))\n",
        "print(\"balanced_accuracy_score:\",balanced_accuracy_score(y_test,preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: [[16384  1370]\n",
            " [ 4348  2798]]\n",
            "accuracy_score: 0.7703614457831325\n",
            "recall_score: 0.3915477190036384\n",
            "f1_score: 0.49460844970832596\n",
            "precision_score: 0.6713051823416507\n",
            "balanced_accuracy_score: 0.6571910049338345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = modelVC.predict(x_train)\n",
        "print(\"confusion matrix:\",confusion_matrix(y_train,preds))\n",
        "print(\"accuracy_score:\",accuracy_score(y_train,preds))\n",
        "print(\"recall_score:\",recall_score(y_train,preds))\n",
        "print(\"f1_score:\",f1_score(y_train,preds))\n",
        "print(\"precision_score:\",precision_score(y_train,preds))\n",
        "print(\"balanced_accuracy_score:\",balanced_accuracy_score(y_train,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlKkq7FvuSJu",
        "outputId": "ab4069b1-9c82-4152-9266-1db5ad12eb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: [[41053   338]\n",
            " [ 5146 11563]]\n",
            "accuracy_score: 0.9056110154905336\n",
            "recall_score: 0.6920222634508348\n",
            "f1_score: 0.8083187696609576\n",
            "precision_score: 0.9715990252919923\n",
            "balanced_accuracy_score: 0.8419281185099841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Lightgbm"
      ],
      "metadata": {
        "id": "xUn5Qo9dKcej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "rbhGuxc-xSnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna \n",
        "import joblib\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "def objective(trial: Trial,X,y) -> float:\n",
        "    \n",
        "    joblib.dump(study, 'study.pkl')\n",
        "\n",
        "    param = {\n",
        "                \"n_estimators\" : trial.suggest_int('n_estimators', 500, 2000),\n",
        "                \"num_leaves\": trial.suggest_int('num_leaves',0,50),\n",
        "                'max_depth':trial.suggest_int('max_depth', 2, 10),\n",
        "                'reg_alpha':trial.suggest_loguniform('reg_alpha', 0.01, 5),\n",
        "                'reg_lambda':trial.suggest_loguniform('reg_lambda', 0.1, 5),\n",
        "                'min_split_gain ':trial.suggest_loguniform('min_split_gain ',0.1,5),\n",
        "                'min_child_samples':trial.suggest_int('min_child_samples',0,50),\n",
        "                'min_child_weight':trial.suggest_loguniform('min_child_weight', 0.01, 5),\n",
        "                'learning_rate':trial.suggest_loguniform('learning_rate',0.05,0.5)\n",
        "            }\n",
        "    \n",
        "    model = LGBMClassifier(**param)\n",
        "    \n",
        "    return cross_val_score(model, X, y, cv=3,scoring='roc_auc').mean()\n",
        "  \n",
        "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
        "study.optimize(lambda trial : objective(trial,x_train,y_train),n_trials= 10)\n",
        "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbCYeNVSMk1n",
        "outputId": "f74cfc70-2857-44cb-e7aa-29ae69762392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-08 13:49:32,783]\u001b[0m A new study created in memory with name: no-name-84057032-e2bc-47b3-8890-45fa4d11d06d\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:50:09,333]\u001b[0m Trial 0 finished with value: 0.7610047505401436 and parameters: {'n_estimators': 1614, 'num_leaves': 32, 'max_depth': 4, 'reg_alpha': 0.2662089070963447, 'reg_lambda': 0.3558375812889827, 'min_split_gain ': 0.3897623507686775, 'min_child_samples': 2, 'min_child_weight': 0.5097301514414817, 'learning_rate': 0.12519817943726816}. Best is trial 0 with value: 0.7610047505401436.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:50:32,199]\u001b[0m Trial 1 finished with value: 0.756329531537619 and parameters: {'n_estimators': 1085, 'num_leaves': 14, 'max_depth': 9, 'reg_alpha': 0.057734578446689264, 'reg_lambda': 4.1790078093017025, 'min_split_gain ': 4.036711502716259, 'min_child_samples': 39, 'min_child_weight': 0.048840885518998296, 'learning_rate': 0.2445896913349848}. Best is trial 0 with value: 0.7610047505401436.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:50:56,808]\u001b[0m Trial 2 finished with value: 0.7752856486977037 and parameters: {'n_estimators': 637, 'num_leaves': 44, 'max_depth': 10, 'reg_alpha': 0.47041130064476866, 'reg_lambda': 0.18446924483783245, 'min_split_gain ': 0.29938087998914237, 'min_child_samples': 20, 'min_child_weight': 2.2551999981661677, 'learning_rate': 0.051317433883951484}. Best is trial 2 with value: 0.7752856486977037.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:51:21,912]\u001b[0m Trial 3 finished with value: 0.7776051490581731 and parameters: {'n_estimators': 1131, 'num_leaves': 15, 'max_depth': 5, 'reg_alpha': 0.018842055477212634, 'reg_lambda': 0.4678299757860414, 'min_split_gain ': 0.6651124068830108, 'min_child_samples': 3, 'min_child_weight': 0.07485203792795429, 'learning_rate': 0.050574489470863924}. Best is trial 3 with value: 0.7776051490581731.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:52:03,341]\u001b[0m Trial 4 finished with value: 0.7265854559401882 and parameters: {'n_estimators': 1857, 'num_leaves': 38, 'max_depth': 4, 'reg_alpha': 0.011900551757256867, 'reg_lambda': 0.11615243380211106, 'min_split_gain ': 0.3697475702937694, 'min_child_samples': 7, 'min_child_weight': 1.9971547601915545, 'learning_rate': 0.48187422299073834}. Best is trial 3 with value: 0.7776051490581731.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:52:34,701]\u001b[0m Trial 5 finished with value: 0.7732649521111395 and parameters: {'n_estimators': 1160, 'num_leaves': 28, 'max_depth': 5, 'reg_alpha': 0.021630909223365153, 'reg_lambda': 0.4026072780935597, 'min_split_gain ': 1.6707224531254783, 'min_child_samples': 43, 'min_child_weight': 0.07354421105773166, 'learning_rate': 0.054051452366466406}. Best is trial 3 with value: 0.7776051490581731.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:52:51,007]\u001b[0m Trial 6 finished with value: 0.7795323234102951 and parameters: {'n_estimators': 520, 'num_leaves': 23, 'max_depth': 9, 'reg_alpha': 2.718845232198025, 'reg_lambda': 0.9115429627575123, 'min_split_gain ': 0.18980558808212342, 'min_child_samples': 8, 'min_child_weight': 0.08656845319374155, 'learning_rate': 0.0574267430794456}. Best is trial 6 with value: 0.7795323234102951.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:53:07,091]\u001b[0m Trial 7 finished with value: 0.7755971400251135 and parameters: {'n_estimators': 917, 'num_leaves': 8, 'max_depth': 10, 'reg_alpha': 0.03048579141300891, 'reg_lambda': 0.4487069832657961, 'min_split_gain ': 2.034825949228168, 'min_child_samples': 50, 'min_child_weight': 0.6342424167314739, 'learning_rate': 0.12130198621370943}. Best is trial 6 with value: 0.7795323234102951.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:53:39,958]\u001b[0m Trial 8 finished with value: 0.7359359602775851 and parameters: {'n_estimators': 1454, 'num_leaves': 17, 'max_depth': 8, 'reg_alpha': 0.21283786092358162, 'reg_lambda': 0.3315833359365312, 'min_split_gain ': 3.788833895244729, 'min_child_samples': 19, 'min_child_weight': 3.297800270381785, 'learning_rate': 0.3947038318468334}. Best is trial 6 with value: 0.7795323234102951.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 13:53:59,615]\u001b[0m Trial 9 finished with value: 0.7803385557894894 and parameters: {'n_estimators': 1855, 'num_leaves': 2, 'max_depth': 10, 'reg_alpha': 0.021789970165365304, 'reg_lambda': 0.45751746262521453, 'min_split_gain ': 1.0176210979535125, 'min_child_samples': 5, 'min_child_weight': 0.3010481694037891, 'learning_rate': 0.11912799020355966}. Best is trial 9 with value: 0.7803385557894894.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.7803385557894894,\n",
            "params {'n_estimators': 1855, 'num_leaves': 2, 'max_depth': 10, 'reg_alpha': 0.021789970165365304, 'reg_lambda': 0.45751746262521453, 'min_split_gain ': 1.0176210979535125, 'min_child_samples': 5, 'min_child_weight': 0.3010481694037891, 'learning_rate': 0.11912799020355966}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'n_estimators': 1855, 'num_leaves': 2, 'max_depth': 10, 'reg_alpha': 0.021789970165365304, 'reg_lambda': 0.45751746262521453, 'min_split_gain ': 1.0176210979535125, 'min_child_samples': 5, 'min_child_weight': 0.3010481694037891, 'learning_rate': 0.11912799020355966}\n",
        "lgclf = lgb.LGBMClassifier(**param)\n",
        "lgclf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "jVo6kZUTxdJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23266a6-073b-4d40-8f7f-cec2b1b33159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(learning_rate=0.11912799020355966, max_depth=10,\n",
              "               min_child_samples=5, min_child_weight=0.3010481694037891,\n",
              "               min_split_gain =1.0176210979535125, n_estimators=1855,\n",
              "               num_leaves=2, reg_alpha=0.021789970165365304,\n",
              "               reg_lambda=0.45751746262521453)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = lgclf.predict(x_test)\n",
        "print(\"confusion matrix:\",confusion_matrix(y_test,preds))\n",
        "print(\"accuracy_score:\",accuracy_score(y_test,preds))\n",
        "print(\"recall_score:\",recall_score(y_test,preds))\n",
        "print(\"f1_score:\",f1_score(y_test,preds))\n",
        "print(\"precision_score:\",precision_score(y_test,preds))\n",
        "print(\"balanced_accuracy_score:\",balanced_accuracy_score(y_test,preds))"
      ],
      "metadata": {
        "id": "lY4ZmFNDxTc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61232430-b7b8-43d0-f20f-64d14e3baa2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: [[16298  1456]\n",
            " [ 4178  2968]]\n",
            "accuracy_score: 0.7737349397590362\n",
            "recall_score: 0.4153372516092919\n",
            "f1_score: 0.5130509939498704\n",
            "precision_score: 0.6708860759493671\n",
            "balanced_accuracy_score: 0.6666637818258243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzry__AdDOyP"
      },
      "source": [
        "test_preds = model.predict(test_df_copy)\n",
        "test_df['default_ind'] = test_preds\n",
        "test_df[['application_key','default_ind']].astype(int).to_csv(\"submission4.csv\",index=False,header=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}